import { Embeddings } from "@langchain/core/embeddings";
import { MemoryVectorStore } from "@langchain/classic/vectorstores/memory";
import { RecursiveCharacterTextSplitter } from "@langchain/textsplitters";
import { Document } from "@langchain/core/documents";
import fs from "fs";
import path from "path";

/**
 * ========== ç¬¬å…­è¯¾ï¼šRAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ ==========
 *
 * æœ¬æ¨¡å—å®ç°äº†ä¸¤ç§æ£€ç´¢æ–¹æ¡ˆï¼š
 *
 * 1. å‘é‡æ£€ç´¢ï¼ˆä¸»æ–¹æ¡ˆï¼‰
 *    ç”¨ @huggingface/transformers åœ¨æœ¬åœ°è¿è¡Œ Embedding æ¨¡å‹ï¼Œ
 *    æŠŠæ–‡å­—è½¬æˆå‘é‡ï¼Œç”¨ä½™å¼¦ç›¸ä¼¼åº¦æœç´¢ã€‚
 *    ä¼˜ç‚¹ï¼šç†è§£è¯­ä¹‰ï¼Œ"å¹´å‡" â‰ˆ "ä¼‘å‡"
 *
 * 2. BM25 å…³é”®è¯æ£€ç´¢ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
 *    ç»å…¸ä¿¡æ¯æ£€ç´¢ç®—æ³•ï¼ŒåŸºäºè¯é¢‘åŒ¹é…ã€‚
 *    ä¼˜ç‚¹ï¼šé›¶ä¾èµ–ï¼Œé€Ÿåº¦å¿«
 *
 * ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µï¼šæ··åˆæ£€ç´¢ = å‘é‡æ£€ç´¢ + BM25ï¼Œå…ˆç²—ç­›å†ç²¾æ’ã€‚
 */

// ========================================
// ä¸€ã€å‘é‡æ£€ç´¢ï¼ˆ@huggingface/transformersï¼‰
// ========================================

/**
 * æœ¬åœ° Embedding æ¨¡å‹
 *
 * ç”¨ @huggingface/transformers åœ¨æœ¬åœ°è¿è¡Œ all-MiniLM-L6-v2 æ¨¡å‹
 * è¿™ä¸ªæ¨¡å‹åªæœ‰ 23MBï¼Œä¸“é—¨ç”¨äºæ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—ï¼Œè¾“å‡º 384 ç»´å‘é‡
 *
 * ç¬¬ä¸€æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹å¹¶ç¼“å­˜ï¼Œä¹‹åä¸éœ€è¦å†ä¸‹è½½
 */
class LocalEmbeddings extends Embeddings {
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  private pipe: any = null;

  constructor() {
    super({});
  }

  private async getPipeline() {
    if (!this.pipe) {
      console.log("ğŸ§  æ­£åœ¨åŠ è½½ Embedding æ¨¡å‹ï¼ˆé¦–æ¬¡éœ€è¦ä¸‹è½½ ~23MBï¼‰...");
      const { pipeline, env } = await import("@huggingface/transformers");

      // ä½¿ç”¨ HuggingFace å›½å†…é•œåƒï¼Œè§£å†³ä¸‹è½½è¶…æ—¶é—®é¢˜
      // å¦‚æœä½ èƒ½ç›´è¿ HuggingFaceï¼Œå¯ä»¥æ³¨é‡Šæ‰è¿™è¡Œ
      env.remoteHost = "https://hf-mirror.com";

      this.pipe = await pipeline(
        "feature-extraction",           // ä»»åŠ¡ç±»å‹ï¼šæå–æ–‡æœ¬ç‰¹å¾å‘é‡
        "Xenova/all-MiniLM-L6-v2",     // æ¨¡å‹ï¼šå°å·§é«˜æ•ˆçš„æ–‡æœ¬ç›¸ä¼¼åº¦æ¨¡å‹
        { dtype: "fp32" }
      );
      console.log("ğŸ§  Embedding æ¨¡å‹åŠ è½½å®Œæˆï¼");
    }
    return this.pipe;
  }

  async embedDocuments(texts: string[]): Promise<number[][]> {
    const pipe = await this.getPipeline();
    const results: number[][] = [];
    for (const text of texts) {
      const output = await pipe(text, { pooling: "mean", normalize: true });
      results.push(Array.from(output.data as Float32Array));
    }
    return results;
  }

  async embedQuery(text: string): Promise<number[]> {
    const [result] = await this.embedDocuments([text]);
    return result;
  }
}

// ========================================
// äºŒã€BM25 å…³é”®è¯æ£€ç´¢ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
// ========================================

interface BM25Chunk {
  content: string;
  source: string;
  tokens: string[];
}

function tokenize(text: string): string[] {
  const stopWords = new Set([
    "çš„", "äº†", "åœ¨", "æ˜¯", "æˆ‘", "æœ‰", "å’Œ", "å°±",
    "ä¸", "äºº", "éƒ½", "ä¸€", "ä¸€ä¸ª", "ä¸Š", "ä¹Ÿ", "å¾ˆ",
    "åˆ°", "è¯´", "è¦", "å»", "ä½ ", "ä¼š", "ç€", "æ²¡æœ‰",
    "çœ‹", "å¥½", "è‡ªå·±", "è¿™",
  ]);
  return text
    .replace(/[ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š""''ï¼ˆï¼‰ã€ã€‘\s\n\r]/g, " ")
    .split(/\s+/)
    .filter((w) => w.length >= 2 && !stopWords.has(w))
    .map((w) => w.toLowerCase());
}

function bm25Score(
  queryTokens: string[],
  docTokens: string[],
  avgDocLen: number,
  totalDocs: number,
  docFrequency: Map<string, number>
): number {
  const k1 = 1.5;
  const b = 0.75;
  const docLen = docTokens.length;
  const termFreq = new Map<string, number>();
  for (const token of docTokens) {
    termFreq.set(token, (termFreq.get(token) || 0) + 1);
  }
  let score = 0;
  for (const queryToken of queryTokens) {
    const tf = termFreq.get(queryToken) || 0;
    if (tf === 0) continue;
    const df = docFrequency.get(queryToken) || 0;
    const idf = Math.log((totalDocs - df + 0.5) / (df + 0.5) + 1);
    const tfNorm = (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * (docLen / avgDocLen)));
    score += idf * tfNorm;
  }
  return score;
}

// ========================================
// ä¸‰ã€çŸ¥è¯†åº“ç®¡ç†ï¼ˆç»Ÿä¸€å…¥å£ï¼‰
// ========================================

let vectorStore: MemoryVectorStore | null = null;
let bm25Chunks: BM25Chunk[] = [];
let isInitialized = false;
let isInitializing = false;
let useVectorSearch = true; // æ˜¯å¦ä½¿ç”¨å‘é‡æ£€ç´¢

/** åŠ è½½å¹¶åˆ‡åˆ†æ–‡æ¡£ï¼ˆä¸¤ç§æ–¹æ¡ˆå…±ç”¨ï¼‰ */
async function loadAndSplitDocuments(): Promise<Document[]> {
  const knowledgeDir = path.join(process.cwd(), "knowledge");
  if (!fs.existsSync(knowledgeDir)) {
    console.log("âš ï¸ knowledge/ ç›®å½•ä¸å­˜åœ¨");
    return [];
  }

  const files = fs.readdirSync(knowledgeDir).filter((f) => f.endsWith(".txt"));
  const documents: Document[] = [];

  for (const file of files) {
    const content = fs.readFileSync(path.join(knowledgeDir, file), "utf-8");
    documents.push(new Document({ pageContent: content, metadata: { source: file } }));
  }
  console.log(`ğŸ“„ åŠ è½½äº† ${documents.length} ä¸ªæ–‡æ¡£`);

  const splitter = new RecursiveCharacterTextSplitter({
    chunkSize: 300,
    chunkOverlap: 50,
  });
  const chunks = await splitter.splitDocuments(documents);
  console.log(`âœ‚ï¸  åˆ‡åˆ†æˆ ${chunks.length} ä¸ªæ–‡æœ¬å—`);

  return chunks;
}

/** åˆå§‹åŒ–çŸ¥è¯†åº“ */
async function initKnowledgeBase() {
  if (isInitialized) return;
  if (isInitializing) {
    while (isInitializing) {
      await new Promise((resolve) => setTimeout(resolve, 100));
    }
    return;
  }

  isInitializing = true;
  console.log("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–çŸ¥è¯†åº“...");

  try {
    const chunks = await loadAndSplitDocuments();
    if (chunks.length === 0) {
      isInitialized = true;
      return;
    }

    // å…ˆå»º BM25 ç´¢å¼•ï¼ˆä¸€å®šèƒ½æˆåŠŸï¼‰
    bm25Chunks = chunks.map((doc) => ({
      content: doc.pageContent,
      source: doc.metadata.source as string,
      tokens: tokenize(doc.pageContent),
    }));

    // å†å°è¯•å‘é‡æ£€ç´¢ï¼ˆå¯èƒ½å› ä¸ºç½‘ç»œé—®é¢˜å¤±è´¥ï¼‰
    try {
      console.log("ğŸ§  æ­£åœ¨æ„å»ºå‘é‡ç´¢å¼•...");
      const embeddings = new LocalEmbeddings();
      vectorStore = await MemoryVectorStore.fromDocuments(chunks, embeddings);
      useVectorSearch = true;
      console.log("âœ… çŸ¥è¯†åº“åˆå§‹åŒ–å®Œæˆï¼ˆå‘é‡æ£€ç´¢æ¨¡å¼ï¼‰ï¼");
    } catch (error) {
      console.warn("âš ï¸ å‘é‡æ£€ç´¢åˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€åˆ° BM25 æ¨¡å¼:", error);
      useVectorSearch = false;
      console.log("âœ… çŸ¥è¯†åº“åˆå§‹åŒ–å®Œæˆï¼ˆBM25 æ¨¡å¼ï¼‰ï¼");
    }

    isInitialized = true;
  } finally {
    isInitializing = false;
  }
}

/** å‘é‡æ£€ç´¢ */
async function vectorSearch(query: string, topK: number): Promise<string> {
  if (!vectorStore) return "";
  const results = await vectorStore.similaritySearch(query, topK);
  if (results.length === 0) return "";
  return results
    .map((doc) => `ã€æ¥æº: ${doc.metadata.source} | æ–¹å¼: å‘é‡æ£€ç´¢ã€‘\n${doc.pageContent}`)
    .join("\n\n---\n\n");
}

/** BM25 æ£€ç´¢ */
function bm25Search(query: string, topK: number): string {
  if (bm25Chunks.length === 0) return "";
  const queryTokens = tokenize(query);
  const docFrequency = new Map<string, number>();
  for (const chunk of bm25Chunks) {
    const uniqueTokens = new Set(chunk.tokens);
    for (const token of uniqueTokens) {
      docFrequency.set(token, (docFrequency.get(token) || 0) + 1);
    }
  }
  const avgDocLen = bm25Chunks.reduce((sum, c) => sum + c.tokens.length, 0) / bm25Chunks.length;
  const scored = bm25Chunks.map((chunk) => ({
    ...chunk,
    score: bm25Score(queryTokens, chunk.tokens, avgDocLen, bm25Chunks.length, docFrequency),
  }));
  scored.sort((a, b) => b.score - a.score);
  const topResults = scored.slice(0, topK).filter((r) => r.score > 0);
  if (topResults.length === 0) return "";
  return topResults
    .map((r) => `ã€æ¥æº: ${r.source} | æ–¹å¼: BM25 | åˆ†æ•°: ${r.score.toFixed(2)}ã€‘\n${r.content}`)
    .join("\n\n---\n\n");
}

/** æœç´¢çŸ¥è¯†åº“ï¼ˆå¯¹å¤–æš´éœ²çš„ç»Ÿä¸€æ¥å£ï¼‰ */
export async function searchKnowledge(query: string, topK: number = 3): Promise<string> {
  await initKnowledgeBase();

  if (bm25Chunks.length === 0) {
    return "çŸ¥è¯†åº“ä¸ºç©ºï¼Œè¯·åœ¨ knowledge/ ç›®å½•ä¸‹æ·»åŠ  .txt æ–‡ä»¶ã€‚";
  }

  // ä¼˜å…ˆç”¨å‘é‡æ£€ç´¢ï¼Œå¤±è´¥æˆ–ä¸å¯ç”¨æ—¶å›é€€ BM25
  if (useVectorSearch && vectorStore) {
    try {
      const result = await vectorSearch(query, topK);
      if (result) return result;
    } catch (error) {
      console.warn("å‘é‡æ£€ç´¢å‡ºé”™ï¼Œå›é€€åˆ° BM25:", error);
    }
  }

  const result = bm25Search(query, topK);
  if (result) return result;

  return "çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ä¸é—®é¢˜ç›¸å…³çš„ä¿¡æ¯ã€‚";
}
